# 20240412 pjt 5회차 필기

## 웹 크롤링

### 파이썬으로 웹 페이지에 있는 정보를 가져오는 방법
1. 누군가가 업로드해 둔 데이터를 다운로드 받기 (ex. 캐글)
2. 누군가 만들어 둔 API Server를 활용하여 정보를 받아오기
3. 사람이 검색하는 것처럼 파이썬이 자동으로 검색 후 결과를 수집하는 방법
    - 이러한 기술을 크롤링이라고 한다.

### 웹 크롤링이란?
- 여러 웹 페이지를 돌아다니며 원하는 정보를 모으는 기술
- 원하는 정보를 추출하는 스크래핑(Scraping)과 여러 웹 페이지를 자동으로 탐색하는 크롤링(Crwaling)의 개념을 합쳐 웹 크롤링이라고 부름
- 즉, 웹 사이트들을 돌아다니며 필요한 데이터를 추출하여 활용할 수 있도록 자동화된 프로세스

### 웹 크롤링 프로세스
- 웹 페이지 다운로드
  - 해당 웹 페이지의 HTML, CSS, JavaScript 등의 코드를 가져오는 단계
- 페이지 파싱
  - 다운로드 받은 코드를 분석하고 필요한 데이터를 추출하는 단계
- 링크 추출 및 다른 페이지 탐색
  - 다른 링크를 추출하고, 다음 단계로 이동하여 원하는 데이터를 추출하는 단계
- 데이터 추출 및 저장
  - 분석 및 시각화에 사용하기 위해 데이터를 처리하고 저장하는 단계

## 실습

### 준비 단계
- 필수 라이브러리
  - requests : HTTP 요청을 보내고 응답을 받을 수 있는 모듈
  - BeautifulSoup : HTML 문서에서 원하는 데이터를 추출하는 데 사용되는 파이썬 라이브러리
  - Selenium : 웹 애플리케이션을 테스트하고 자동화하기 위한 파이썬 라이브러리
    - 웹 페이지의 동적인 컨텐츠를 가져오기 위해 사용함 (검색 결과 등)
- `pip install requests beautifulsoup4 selenium`

### 기본 예제 실습
- Quotes to Scrape 사이트 활용
- requests 및 BeautifulSoup 라이브러리 활용 연습

### BeautifulSoup4 요소 선택 메서드 종류
- find() : 태그를 사용하여 요소를 검색. 첫 번째로 일치하는 요소를 반환
- find_all() : 태그를 사용하여 요소를 검색. 모든 일치하는 요소를 리스트로 반환
- select() : CSS 선택자를 사용하여 요소를 검색. 모든 일치하는 요소를 리스트로 반환
- select_one() : CSS 선택자를 사용하여 요소를 검색. 첫 번째로 일치하는 요소를 반환
- find_parent() / find_next_sibling() / find_previous_sibling() : 태그를 사용하여 요소를 검색. 각각 일치하는 요소의 부모/ 다음형제요소/ 이전형제요소를 반환

## Django에서의 활용

### Model 작성
```python
# models.py

class Article(models.Model):
    # 게시글 검색후 title
    title = models.TextField()

class Query(models.Model):
    # 외래키로 article을 가짐, 1:N
    article = models.ForienKey(Article, on_delete=CASCADE)

    # 검색의 keyword
    keyword = models.TextField()
```

### View 작성
```python
# views.py

def get_data(keyword):
    url = f'https://www.google.com/search?q={keyword}'
    ...
    # 검색
    return result

def crawling(request):
    keyword = '탕수육'
    titles = get_data(keyword)
    for title in titles:
      # get_or_create : 있다면 조회, 없다면 생성
      # 1. article 저장
      #   - 기존에 이미 저장된 article 이면 pass
      article, created_article = Article.objects.get_or_create(title=title)

      # 2. keywoord 저장
      # 기존에 이미 저장된 keyword라면 pass
      query_obj, created_query = Query.objects.get_or_create(article=article, keyword=keyword)
```